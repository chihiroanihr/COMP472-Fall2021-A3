{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "directory = cwd + \"/outputs/\"\n",
    "analysis_path = directory + 'analysis.csv'\n",
    "\n",
    "# new dataframe created to system model analysis\n",
    "analysis_df = pd.DataFrame(columns=['model_info', 'corpus_size', '#correct_labels', '#questions_answered_no_guess', 'accuracy_model'])\n",
    "\n",
    "\n",
    "# initialize appendable analysis.csv file\n",
    "def initialize_file():\n",
    "    if(os.path.exists(analysis_path) and os.path.isfile(analysis_path)):\n",
    "        os.remove(analysis_path)\n",
    "        print(\"analysis.csv file initialized\")\n",
    "\n",
    "\n",
    "# read all result csv files from outputs folder\n",
    "def read_csv():\n",
    "    available_models = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"): \n",
    "            df = pd.read_csv(directory + filename)\n",
    "            available_models[filename] = df\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "    return available_models\n",
    "\n",
    "\n",
    "# create new analysis dataframe\n",
    "def analysis(model, model_path):\n",
    "    vocab_size = len(model)     # size of the vocabulary(corpus) in model\n",
    "    num_labels_dict = model[\"label\"].value_counts()    # returns dictionary with frequency elements in all labels\n",
    "    num_correct_labels = num_labels_dict[\"correct\"]         # number of all elements with correct label\n",
    "    V = num_labels_dict[\"correct\"] + num_labels_dict[\"wrong\"]   # number of all elements with no guess label\n",
    "    accuracy_model_val = num_correct_labels / V             # accuracy model value (C/V)\n",
    "    \n",
    "    model_name = model_path.strip(\"-details.csv\")\n",
    "    name = model_name.rsplit('-', 1)[0]\n",
    "    embedding_size = model_name.rsplit('-', 1)[1]\n",
    "    model_info = name + \"-\" + str(embedding_size)\n",
    "    \n",
    "    # append all the data (model_name, corpus_size, #correct_labels, #questions_answered_no_guess, accuracy_model) \n",
    "    # to new dataframe\n",
    "    analysis_df.loc[0] = [model_info, vocab_size, num_correct_labels, V, accuracy_model_val]\n",
    "    \n",
    "    return analysis_df\n",
    "\n",
    "\n",
    "# save dataframe to analysis.csv file\n",
    "def save(analysis_df, model_name):\n",
    "    # save model analysis to -analysis.csv\n",
    "    if os.path.exists(analysis_path):\n",
    "        analysis_df.to_csv(analysis_path, mode='a', header=False, index=False)\n",
    "        print(model_name + \" info successfully stored in analysis.csv\")\n",
    "    else:\n",
    "        analysis_df.to_csv(analysis_path, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # initialize appendable analysis.csv file (delete all data from last session)\n",
    "    initialize_file()\n",
    "    \n",
    "    # read all result csv files returned from executing models\n",
    "    available_models = read_csv()\n",
    "    \n",
    "    # create new analysis dataframe for each models and save to csv file\n",
    "    for model_name, model in available_models.items():\n",
    "        analysis_df = analysis(model, model_name)\n",
    "        save(analysis_df, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis.csv file initialized\n",
      "glove-twitter-25-details.csv info successfully stored in analysis.csv\n",
      "glove-twitter-50-details.csv info successfully stored in analysis.csv\n",
      "glove-wiki-gigaword-200-details.csv info successfully stored in analysis.csv\n",
      "word2vec-google-news-300-details.csv info successfully stored in analysis.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b57f895460dec02687b9e5a92e8158b77d00a27c68f06b1b3c2207406ad9da89"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('env64': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
